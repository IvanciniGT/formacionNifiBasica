
# Conectarnos a una bbdd relacional.

Queremos conectar desde nifi con Postgres (serÃ­a igual con Oracle, MySQL, SQL Server).

NIFI estÃ¡ desarrollado en JAVA.

En java hay una colecciÃ³n de estÃ¡ndares para el desarrollo de aplicaciones: JEE (Jakarta enterprise edition).
Dentro de esa colecciÃ³n hay un estandar llamado JDBC.
Ese estandar define un PROTOCOLO para comunicar con BBDD Relacionales de JAVA.

Cualquier Base de datos relacional nos permite conectarnos con ella mediante ese protocolo jdbc.
Pero, para ello, necesitamos disponer del DRIVER DE CONEXION a la BBDD. Esto es un programa JAVA (extensiÃ³n .jar)
Cada fabricante de BBDD provee el driver JAVA que soporta protocolo JDBC de su base de datos.

Ese driver lo necesita NIFI.
Para conectarse a la BBDD, ademÃ¡s del driver, hemos de dar la CADENA DE CONEXION con protocolo jdbc.

    jdbc:mariadb://localhost:3306/DB?user=root&password=myPassword

Hay otra cosa. En java, un archivo .jar realmente es un archivo .zip con la extensiÃ³n cambiada.
Dentro incluyen decenas o cientos de archivos.
Uno de ellos es el principal. El fabricante tambiÃ©n me debe decir cuÃ¡l es ese archivo proncipal dentro del .jar.
Eso se llama el Driver Class Name: org.postgresql.Driver

                    Dentro del archivo zip, hay una carpeta llamada org, 
                    que dentro tiene una carpeta llamada postgresql que dentro tiene un archivo llamado Driver
                    
Esos 3 datos son criticos:
- Driver (fichero .jar)
- Fichero principal del driver (que viene dentro del .jar... que es un .zip relamente)
- Cadena de conexiÃ³n: Connection String (URL)

AdemÃ¡s:
- Usuario
- Password

---

Cuando trabajamos contra una BBDD relacional, y somos una aplicaciÃ³n, que va a estar corriendo en un entorno de producciÃ³n, no estamos abriendo conexiones contra la BBDD.

Con un cliente de BBDD, es lo que hacemos. Cuando en el adminer hemos entrado con nuestro usuario y contraseÃ±a,
el adminer se crea una conexiÃ³n a la BBDD.. Y la mantiene abierta mientras estoy dentro ejecutando comandos.

Pero una app que conecta con una BBDD nunca hace eso. De hecho el hacerlo serÃ­a una MUY MALA PRACTICA.
A nivel de una BBDD abrir una conexiÃ³n que implica? La BBDD cuando abre una conexiÃ³n no abre un hilo... abre un PROCESO COMPLETO A NIVEL DE SO.
A nivel de JAVA (en una app que estoy montando), abrir una conexiÃ³n a BBDD que implica? JAVA abre un THREAD (hilo de ejecuciÃ³n asociado a la conexiÃ³n).

Lo que hacemos siempre es utilizar un POOL DE CONEXIONES (Connection pool).
Abriremos un nÃºmero inicial de conexiones (en nuestro caso, en NIFI)... y las mantenemos abiertas.
Cualquiera que necesite conectar a la BBDD (por ejemplo un procesador X que quiera hacer una query para sacar datos
o un procesador Y que quiera escribir en la BBDD) pide prestada una conexiÃ³n a ese pool.

Una vez que ha terminado su trabajo, libera de vuelta la conexiÃ³n al pool, para que otro programa (procesador) pueda utilizarla.

Esos pool de conexiones, al configurarlos, les asignamos un tamaÃ±o inicial... aunque podemos pedir que si hay mucha carga de trabajo que se incremente dinamicamente el nÃºmero de conexiones del pool.

Desde BBDD me van a capar el nÃºmero de conexiones que puedo abrir.

De vuelta a NIFI... quien necesita conexiones a la BBDD de turno (oracle, postgres...) son los PROCESADORES.
Hay varios procesadores que nos permiten trabajar con BBDD relacionales.

Pero... esos procesadores necesitan de una conexiÃ³n a la BBDD. Esa conexiÃ³n se obtendrÃ¡ de un POOL de conexiones.

DÃ³nde se configura ese pool de conexiones? En un Service Controller.

---

/compartida/driver/postgresql-42.7.5.jar

jdbc:postgresql://172.31.32.23:5432/db

---

Los procesos que montamos en nifi, van a tener muchas tareas intermedias... Quiero independizarlas: DESACOPLARLAS

                                    ????                    ????
    Leo de una BBDD             Lo transformo           Lo envÃ­o a un servicio WEB
                    ---> JSON               ---> JSON
                    
                    
    Muchas veces traemos datos de sistemas y los queremos procesar por otros sistemas.
    Pero puede ser que esos otros sistemas no estÃ©n operativos.
    
        BBDD ---> Servicio Web
         E.   T.    L
         
    Pero el servicio WEB no estÃ¡ operativo
                                                        1000/segundo
                         FF1(AVRO)                      FF1'(JSON)
    
                                                                retries (3)
        ExecuteSQL ----> COLA ----> ConvertRecord ----> COLA ----> EnvÃ­a al Servicio Web ----> ERROR
                                                        Memoria                 |
                                                                                v
                                                                             SUCCESS
                    
    Podemos pensar que estamos mÃ¡s o menos a salvo con las COLAS DE NIFI.                

Imaginad que el dato en origen cambia(En BBDD ahora las columnas tienen otro nombre)

Las COLAS DE NIFI son "colitas"... sirven para dejar ahÃ­ 4 datos.
Si quiero tener colas (PERSISTENCIA en caso de problemas) necesito un producto que realmente maneje COLAS: KAFKA


Al desacoplar trabajos:
1. Facilitamos el desarrollo. Un procesador (processgroup).. En definitiva un trabajo tiene un scope MUY LIMITADO
   (hace algo muy concreto)
2. Facilitamos el mantenimiento del sistema completo. Cada cola que pongo es una barrera de contenciÃ³n ante cambios.
   Si se produce un cambio en los datos (o en la forma de procesarlos)... con asegurarme que el formato FINAL que deposito en la cola sea el mismo que antes, no hace falta TOCAR NADA MAS del proceso completo!
3. En caso de caÃ­da de una parte del sistema, no pierdo datos...

De entrada en una de esas colas.. los datos pueden quedar almacenados bastante tiempo. Me interesa un formato que ocupe poco espacio: BINARIO
Por las mismas, teniendo en cuenta que la naturaleza del dato puede cambiar (si es asÃ­, habrÃ¡ escenarios donde no), el incorporar al dato el esquema, me da garantÃ­as de que en el futuro serÃ© capaz de entender el dato.

Hay otros motivos para guardar datos de forma mÃ¡s persistente: 
- AUDITORIA
- BUSINESS INTELLIGENCE

En estos escenarios, me suele interesar un formato de datos orientado a COLUMNAS, no a filas
    JSON, XML, CSV, AVRO van orientados a filas -> TRATAMIENTO DE DATOS UNO A UNO
    PARQUET (binario) va orientado a columnas
                
                
                
## AVRO

Objavro.schemaÃ¢
    {
        "type":"record",
        "name":"personas",
        "namespace":"any.data",
        "fields":[
            {"name":"id","type":["null","int"]},
            {"name":"empresaid","type":["null","int"]},
            {"name":"numero_dni","type":["null","int"]},
            {"name":"letra_dni","type":["null","string"]},
            {"name":"nombre","type":["null","string"]},
            {"name":"apellidos","type":["null","string"]},
            {"name":"email","type":["null","string"]}]}
avro.codecnullï¿½Â¥X|()Ã¾Â©Ã¿â€Ã·â„¢PjÃŠ

    Â°Ã§TIvanOsunaivan@ivan.com
    Â°Ã§TLuisGarcÃƒÂ­aivan@ivan.com
    Â°Ã§TRuthNÃƒÂºÃƒÂ±ezivan@ivan.com
    Â°Ã§TFernÃƒÂ¡nEstebanivan@ivan.com

Â¥X|()Ã¾Â©Ã¿â€Ã·â„¢Pj


[
    {"id":1,"empresaid":1,"numero_dni":23000,"letra_dni":"T","nombre":"Ivan","apellidos":"Osuna","email":"ivan@ivan.com"},
    {"id":2,"empresaid":1,"numero_dni":23000,"letra_dni":"T","nombre":"Luis","apellidos":"GarcÃ­a","email":"ivan@ivan.com"},
    {"id":3,"empresaid":1,"numero_dni":23000,"letra_dni":"T","nombre":"Ruth","apellidos":"NÃºÃ±ez","email":"ivan@ivan.com"},
    {"id":4,"empresaid":2,"numero_dni":23000,"letra_dni":"T","nombre":"FernÃ¡n","apellidos":"Esteban","email":"ivan@ivan.com"}
]

---

                  AVRO      READER: AVRO ---> WRITER: AVRO
Saque datos de un Kafka, los transforme y los:
- Guarde en una BBDD (WRITER: internamente los guarda en su formato).   READER
- Los envÃ­e a un Servicio Web   (WRITER: JSON)                          READER (ARVO)
- 


        Este avro  (serÃ­aiguala) ESTO OTRO?
         vv                     vv
                                    --> (JSON) --> Servicio Web
KAFKA -> AVRO -> TRANSFORMO -> AVRO --> BBDD
                    ^^^
                    AÃ±adir 3 datos nuevos
                    (Enriquecer el documento)


